# -*- coding: utf-8 -*-
"""Whole State Absentee_Percent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q8DYG8QZTGYgcJWwpd74Mby1PTZSRxPf
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
from scipy.stats import chi2
import os
import statsmodels.formula.api as sm
os.listdir()

#Use if the database above does not have gdrive as an option
from google.colab import drive
drive.mount("/content/gdrive")
os.listdir()
#desired output: ['.config', 'gdrive', 'sample_data']

#os.chdir("../Precinct analysis")
os.chdir("gdrive/MyDrive/Test Databasing/Precinct analysis")
os.listdir()[0:4]
#This should print out the file you search for

df = pd.read_csv('totalElection3.csv')
print(df.keys())

#Gives a heat map of the correlation between variables
import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(df.corr(), cmap="PiYG")

import scipy.stats as st
from scipy.stats import chi2
from tqdm import tnrange, tqdm_notebook


def regress(yvar, xvar, prin = 0):
  form = str(yvar) + "~"
  #form += "County1Fulton" + "+" + "difTrumpPercInPerson" + "+"
  for var in xvar:
    form += var + "+"
  #form += "0"
  form = form[0:-1]
  result = sm.ols(formula= form, data=df).fit()
  if prin == 1:
    print(result.summary())
    print("R^2: ", result.rsquared_adj)
    print("AIC: ", result.aic)
    print("BIC: ", result.bic)
  return result.rsquared
regress('percentTrumpAbsentee', ['percentTrumpTotal'])

import itertools
#Used to find the best model; xvar = List of x variables, numvar= how many variables you wish to keep
def regsubset(xvar, numvar):
  xoptions = itertools.combinations(xvar, numvar)
  dic = {}
  for op in xoptions:
    dic[regress('percentTrumpAbsentee', op)] = op
  print(dic)
  regress('percentTrumpAbsentee' , dic[max(dic.keys())], 1)
  #Change back to max
  return dic[max(dic.keys())]
xvar = ['X', 'Y', 'percentMale',
       'percentFemale', 'percentWhite', 'percentBlack', 'percentHispanic',
       'percentAsianPacific', 'percentAmericanIndian', 'percentOther',
       'percentUnknown', 'Twenty_ThirNinePercent', 'Forty_FifNinePercent',
       'SixtyPlusPercent', 'LastVotedDemocrat', 'LastVotedRepublican']
regsubset(xvar, 1)
regsubset(xvar, 2)
regsubset(xvar, 3)
regsubset(xvar, 4)
regsubset(xvar, 5)
regsubset(xvar, 6)
regsubset(xvar, 7)
regsubset(xvar, 8)
regsubset(xvar, 9)
regsubset(xvar, 10)

regsubset(xvar, 14)

df = df[df["percentTrumpAbsentee"] > -2.53740]
#This one is used to grab Standardized residuals for different models
def regress(yvar, xvar, prin = 0): 
  form = str(yvar) + "~"
  #form += "County1Fulton" + "+" + "difTrumpPercInPerson" + "+"
  for var in xvar:
    form += var + "+"
  #form += "0"
  form = form[0:-1]
  result = sm.ols(formula= form, data=df).fit()
  influence = result.get_influence()
  standardized_residuals = influence.resid_studentized_internal
  if prin == 1:
    #print(standardized_residuals)
    #print(result.summary())
    print(result.rsquared_adj)
  df2 = df
  
  df2["Standardized Residuals"] = standardized_residuals
  df2["Prediction"] = result.predict()
  return df2
df2 = regress('percentTrumpAbsentee', xvar = ['Y', 'percentWhite',
       'percentAsianPacific', 'percentAmericanIndian', 
       'percentUnknown', 'LastVotedDemocrat', 'LastVotedRepublican'],prin = 1)
print(df2)
df3 = df2[np.abs(df2["Standardized Residuals"]) > 3][["Unnamed: 0", "Standardized Residuals", 'percentTrumpAbsentee', "Prediction"]]
print(df3)

##Prints Normal Tests
from scipy import stats
from scipy import stats
print("Shapiro: ", stats.shapiro(df2["Standardized Residuals"]))
print("Kolmogorov-Smirnov: ", stats.kstest(df2["Standardized Residuals"], 'norm'))
df2["Standardized Residuals"].plot.hist(grid=True, bins=40, rwidth=0.5,
                   color='#607c8e')

# QQ Plot
from numpy.random import seed
from numpy.random import randn
from statsmodels.graphics.gofplots import qqplot
from matplotlib import pyplot
# q-q plot
qqplot(df2["Standardized Residuals"], line='s')
pyplot.show()